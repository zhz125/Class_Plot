#  Created on Mon Oct  15
#  @author: zheng zhang
#  Second Step of file preparation
#  @purpose: find xlogp for csi, berep, GNPS_anal and GNPS simile candidates for each feature
#            use rcdk to keep the results consistent with ChemRICH
#
#  @input : Default: intermediate_files/with_xlogp.csv (generated by the first step: prepareXlogp.R)
#           User: input_files/t_test.csv,input_files/fold_change.csv
#  @output: intermediate_files/format_toplot.csv, which will be used directly into plot functions

import pandas as pd
import numpy as np
import os
import statistics as st
from scipy import stats
import sys

# Helper Methods
# Helper 1: Iterate through rows of every classes and find all the compounds that has scores above
#           threshold. [DEFAULT: 0.8]
#
#           Then output a string that contains all the compounds considered to be included in the
#           class. Separate each feature by <br>
def select_compounds(ids,row,threshold):
    id_contained = []
    for i,(id,prob) in enumerate(zip(ids,row)):
        if prob>threshold:
            id_contained.append(str(id))
    if len(id_contained)==0:
        return "0"
    return "<br>".join(id_contained)

# Helper 2: Find how many features are in the class
def count_compounds (row):
    return len(row['compounds_ids'].split('<br>'))


# Helper 3: assgin the feature xlogp by the median of csi, derep, gnps_anal and gnps xlogp,
#           these four xlogps were generated in prepareXlogp.R by rcdk.
#
#           @notice: if the value for certain xlogps were not found, it returns the median of
#                    the rest xlogps
def median_xlogp (row):
    return np.nanmedian(np.array([row['xlogp_csi'],row['xlogp_derep'],row['xlogp_GNPS_anal'],row['xlogp_GNPS']]))

#Helper 4: Assign the name of the feature to be one of the candidates
#          The order of search is assigned randomly.
def merge_names(row):
    if row['GNPS_Compound_Name'] == row['GNPS_Compound_Name']:
        return row['GNPS_Compound_Name']
    elif row['DEREP_Name'] == row['DEREP_Name']:
        return row['DEREP_Name']
    elif row['GNPS_ANAL_Compound_Name'] == row['GNPS_ANAL_Compound_Name'] :
        return row['GNPS_ANAL_Compound_Name']
    elif row['CSI_name'] == row['CSI_name']:
        return row['CSI_name']

# Helper 5: assgin the class xlopg by the median of xlogp of all the features in the classes.
def median_compounds_xlogp(xlogp,row,threshold):
    id_contained = []
    for i,(id,prob) in enumerate(zip(xlogp,row)):
        if prob>threshold:
            id_contained.append(float(id))
    if len(id_contained)==0:
        return "0"
    return st.median(id_contained)

# Helper 6: assgin the class pvalues by the ks-test of the feature pvalues.
#           @notice: ks-test only takes in none nan number as pvalues. All features without pvalues are excluded.
#                    Class pvalues were calculated if the set has at least 2 metabolites with less than 0.05 pvalue.
def ks_test_pvalues(pvalues,row,threshold):
    id_contained = []
    for i,(id,prob) in enumerate(zip(pvalues,row)):
        if prob>threshold and not np.isnan(id):
            id_contained.append(float(id))
    # pvalues were calculated if the set has at least 2 metabolites with less than 0.05 pvalue.
    group_p =1
    if len( [i for i in id_contained if i <= 0.05])>1:
        group_p =stats.kstest(np.array(id_contained),"uniform",alternative="greater")[1]
    return group_p


# Helper 7: assgin the class upratio numerator by counting the number of compounds whose fold change
#           is bigger than one and p value is lower than 0.05
def find_upratio(pvalues,fdr,row,threshold):
    count = 0
    for i,(p,f,prob) in enumerate(zip(pvalues,fdr,row)):
        if prob>threshold and not np.isnan(f) and not np.isnan(p):
            if f >1 and p<0.05:
                count += 1
    return float(count)

# main method to generate the desired table
def get_plot_table(t_test_f,fold_change_f):
    
    #read foldchange, t_test results and combine them with the annotated table (with xlogp)
    input = pd.read_csv('intermediate_files/with_xlogp.csv')
    input.set_index('FeatureID',inplace=True)
    t_test = pd.read_csv(t_test_f)
    t_test.set_index('FeatureID',inplace=True)
    fc = pd.read_csv(fold_change_f)
    fc.columns = ['FeatureID','Fold Change','log2(FC)']
    fc.set_index('FeatureID',inplace=True)
    input = pd.concat([input, t_test,fc], axis=1)
    input.reset_index(inplace=True)

    #find the median xlogp for one compounds across four candidate
    input.drop_duplicates(keep=False,inplace=True)
    input['xlogp'] =input.apply(lambda row: median_xlogp(row), axis=1)
    #drop compounds whose xlogp is NA
    #drop compounds whose fold is NA (for better upratio)
    input.dropna(subset = ['xlogp'],inplace=True)
    input.dropna(subset = ['Fold Change'],inplace=True)
    
    #assign feature with compound names
    input['compound_names'] = input.apply(lambda row: merge_names(row), axis = 1)
    #drop compounds whose fold is NA (we use compound name as label in the plot)
    input.dropna(subset = ['compound_names'],inplace=True)
    
    
    #find the compoud names, classes_names, feature_id, pvalues, fdc in the order of feature ids
    #thses variable will be used to find class properties
    compound_names =input['compound_names'].tolist()
    classes_names = [c.split('_')[-1] for c in input.columns if c.startswith('CNP')]
    feature_id =input.FeatureID.tolist()
    pvalues =input['p.value'].tolist()
    fdc = input['Fold Change'].tolist()
    
    #rewrit the score table so that it looks like:
    #classes (feature1) (feature2) (feature3) (feature4)  ...
    #class1   score11    score12    score13   score14     ...
    #class2   score21    score22    score23   score24     ...
    #class3   score31    score32    score33   score34     ...
    # ...
    classes =[c for c in input.columns if c.startswith('CNP')]
    class_df = input[classes].T
    class_df['classes'] = classes_names
    
    #iterate through each row and write names and id columns based on the scores
    class_df['compounds_names'] = class_df.apply (lambda row: select_compounds (compound_names,row,0.8),axis=1)
    class_df['compounds_ids'] = class_df.apply (lambda row: select_compounds (feature_id,row,0.8),axis=1)
    
    #then get the class properties based on the feature properties and features included in the class
    class_df['class_xlogp'] = class_df.apply (lambda row: median_compounds_xlogp (input.xlogp.tolist(),row,0.8),axis=1)
    class_df['csize']= class_df.apply (lambda row: count_compounds (row),axis=1)
    class_df['pvalue']= class_df.apply (lambda row:  ks_test_pvalues(pvalues,row,0.8),axis=1)
    class_df['upratio']= class_df.apply (lambda row:  find_upratio(pvalues,fdc,row,0.8)/float(count_compounds (row)),axis=1)
    
    #write the output table
    output = class_df[["classes","compounds_names","class_xlogp","compounds_ids","csize","pvalue","upratio"]]
    output = output[output.compounds_names !="0"]
    output = output[output.pvalue!=0]
    output = output[output.pvalue!=1]
    output.to_csv('intermediate_files/format_toplot.csv',index = False)

if __name__ == "__main__":
    get_plot_table(sys.argv[1],sys.argv[2])
